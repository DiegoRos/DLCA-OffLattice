{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.markers as mmark\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "from FunctionsDLCA import *\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def blockPrint():\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = None\n",
    "    try:\n",
    "        yield\n",
    "\n",
    "    finally:\n",
    "        sys.stdout = old_stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening Function\n",
    "def soften(arr, steps):\n",
    "    if steps == 0:\n",
    "        steps = 1\n",
    "    new_arr = []\n",
    "    for i in range(0, len(arr), steps):\n",
    "        try:\n",
    "            new_arr.append(np.sum(arr[i:i+steps]) / steps)\n",
    "        except:\n",
    "            continue\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "    # Clusters\n",
    "global lat_size #INT\n",
    "global radius #INT\n",
    "global densities #LIST\n",
    "global colors #LIST\n",
    "colors = [\"black\", \"darkslategrey\", \"teal\", \"royalblue\", \"midnightblue\", \"navy\", \"slateblue\", \"indigo\"]\n",
    "markers = [\"o\", \"^\", \"*\", \"P\", \"x\", \"1\"]\n",
    "global path_seagate\n",
    "path_seagate = \"D:/ASE III Resultados/\"\n",
    "\n",
    "    # File Names\n",
    "global cluster_fn\n",
    "cluster_fn = \"Cluster\"\n",
    "global frac_dim_counts_fn\n",
    "frac_dim_counts_fn = \"FracDimList\" \n",
    "global rg2_mass_t_fn\n",
    "rg2_mass_t_fn = \"RgMassTime\"\n",
    "global mass_time_fn\n",
    "mass_time_fn = \"NumberTime\"\n",
    "global edges_fn\n",
    "edges_fn = \"Edge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Final Results/ResultsOffL.csv\")\n",
    "\n",
    "lat_size = df.lattice_size.unique()\n",
    "lat_size.sort()\n",
    "print(lat_size)\n",
    "\n",
    "radius = 1\n",
    "\n",
    "simulations = dict()\n",
    "simulation_probabilities = dict()\n",
    "simulation_densities = dict()\n",
    "for lat in lat_size:\n",
    "    simulations[lat] = sorted(list(df[df.lattice_size == lat].num_particles.unique()))\n",
    "    simulation_probabilities[lat] = sorted(list(df[df.lattice_size == lat].probability.unique()))\n",
    "    simulation_densities[lat] = [(particles * np.pi * (radius ** 2)) / (4 * (lat ** 2)) for particles in sorted(list(df[df.lattice_size == lat].num_particles.unique()))]\n",
    "\n",
    "print(simulations)\n",
    "print(simulation_probabilities)\n",
    "print(simulation_densities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fractal Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that counts the average number of particles per box in different divisions, calculates the size of these boxes,\n",
    "# and calculates the amount of boxes that contain particles for a given division size.\n",
    "def boxCount(L, particles, x, y):\n",
    "    div = 4 + (4 * (particles <= 8000)) # Sets start division\n",
    "    break_condition = 2 + (2 * (L > 200)) # Sets ending place for amount of divisions\n",
    "    box_count = [] # List containing the amount of boxes with particles\n",
    "    avg_counts = [] # List containing the amount of particles average per box\n",
    "    box_size = [] # List containing the size of the current boxes\n",
    "    while True: # Emulation of do while loop to calculate individual vales to put into previous lists\n",
    "        boxcount = 0\n",
    "        division = L / div\n",
    "\n",
    "        if division < break_condition: # Ends do while loop\n",
    "            break\n",
    "\n",
    "        for i in range(1,div+1):\n",
    "            for j in range(1,div+1):\n",
    "                lower_x = ((i - 1) * division)\n",
    "                upper_x = (i * division)\n",
    "                lower_y = ((j-1) * division)\n",
    "                upper_y = (j * division)\n",
    "                for xi, yi in zip(x, y):\n",
    "                    if lower_x <= xi <= upper_x and lower_y <= yi <= upper_y:\n",
    "                        boxcount += 1\n",
    "                        break # If a box contains 1 particle the code can move on to the next\n",
    "\n",
    "        # Appends found values to the lists\n",
    "        box_count.append(boxcount)\n",
    "        avg_counts.append(particles/boxcount)\n",
    "        box_size.append(division)\n",
    "\n",
    "        print(\"{:.3f} divisions with minimum {}\".format(division, break_condition))\n",
    "\n",
    "        div *= 2\n",
    "\n",
    "    return box_count, avg_counts, box_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "box_count_lat = dict()\n",
    "avg_count_lat = dict()\n",
    "box_sizes_lat = dict()\n",
    "\n",
    "for lat in lat_size:\n",
    "    box_count_lat[lat] = dict()\n",
    "    avg_count_lat[lat] = dict()\n",
    "    box_sizes_lat[lat] = dict()\n",
    "    for particles in simulations[lat]:\n",
    "        box_count_lat[lat][particles] = dict()\n",
    "        avg_count_lat[lat][particles] = dict()\n",
    "        box_sizes_lat[lat][particles] = dict()\n",
    "        \n",
    "        for probability in simulation_probabilities[lat]:\n",
    "            box_counts_list = []\n",
    "            avg_counts_list = []\n",
    "            box_sizes_list = []\n",
    "\n",
    "            text_files = [f for f in os.listdir(path_seagate) if (cluster_fn in f) and (str(int(lat)) in f) and (str(int(particles)) in f) and (str(float(probability)) in f) and not (edges_fn in f)]\n",
    "            if text_files:\n",
    "                box_count_lat[lat][particles][probability] = []\n",
    "                avg_count_lat[lat][particles][probability] = []\n",
    "                box_sizes_lat[lat][particles][probability] = []\n",
    "                print(f\"Computing Fractal Dims for Lat = {lat}, Particles = {particles} and Probability = {probability}\")\n",
    "                for file_i in text_files:\n",
    "                    cluster = np.loadtxt(path_seagate + '/' + file_i, delimiter = ',')\n",
    "\n",
    "                    x, y, index, z = np.hsplit(cluster, cluster.shape[1])\n",
    "                    x = x.flatten()\n",
    "                    y = y.flatten()\n",
    "                    indexes = index.flatten().astype(int)\n",
    "                    largest_cluster = int(stats.mode(indexes).mode)\n",
    "\n",
    "                    x_index = x[np.where(indexes == largest_cluster)]\n",
    "                    y_index = y[np.where(indexes == largest_cluster)]\n",
    "            \n",
    "                    if (len(x_index)/particles) > 0.4:\n",
    "                        with blockPrint():\n",
    "                            box_count, avg_counts, box_size = boxCount(lat, len(x_index), x_index, y_index)\n",
    "                        plt.close('all')\n",
    "\n",
    "                        box_counts_list.append(box_count)\n",
    "                        avg_counts_list.append(avg_counts)\n",
    "                        box_sizes_list.append(box_size)\n",
    "\n",
    "            if box_counts_list:\n",
    "                box_count_avg_p = np.mean(box_counts_list, axis = 0)\n",
    "                avg_count_avg_p = np.mean(avg_counts_list, axis = 0)\n",
    "                box_sizes_avg_p = np.mean(box_sizes_list, axis = 0)\n",
    "                box_count_lat[lat][particles][probability].append(box_count_avg_p)\n",
    "                avg_count_lat[lat][particles][probability].append(avg_count_avg_p)\n",
    "                box_sizes_lat[lat][particles][probability].append(box_sizes_avg_p)\n",
    "\n",
    "print(box_sizes_lat)\n",
    "print(box_count_lat)\n",
    "print(avg_count_lat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# box_sizes_lat_viejo = box_sizes_lat\n",
    "# box_count_lat_viejo = box_count_lat\n",
    "# avg_count_lat_viejo = avg_count_lat\n",
    "\n",
    "\n",
    "# with open(\"box_sizes_lat_count.pkl\", 'wb') as f:\n",
    "#     pickle.dump(box_sizes_lat, f)\n",
    "\n",
    "# with open(\"box_count_lat_count.pkl\", 'wb') as f:\n",
    "#     pickle.dump(box_count_lat, f)\n",
    "\n",
    "# with open(\"avg_count_lat_count.pkl\", 'wb') as f:\n",
    "#     pickle.dump(avg_count_lat, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('box_sizes_lat_count.pkl', 'rb') as f:\n",
    "    box_sizes_lat_file = pickle.load(f)\n",
    "\n",
    "with open('box_count_lat_count.pkl', 'rb') as f:\n",
    "    box_count_lat_file = pickle.load(f)\n",
    "\n",
    "with open('avg_count_lat_count.pkl', 'rb') as f:\n",
    "    avg_count_lat_file = pickle.load(f)\n",
    "\n",
    "print(box_sizes_lat_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Computing logarithm of Lists\")\n",
    "log_box_sizes_lat = dict() # log average box count list\n",
    "log_box_count_lat = dict() # log average average particle count list\n",
    "log_avg_count_lat = dict() # log average box size list\n",
    "\n",
    "for lat in lat_size:\n",
    "    log_box_count_lat[lat] = dict()\n",
    "    log_avg_count_lat[lat] = dict()\n",
    "    log_box_sizes_lat[lat] = dict()\n",
    "    for particles in simulations[lat]:\n",
    "        log_box_count_lat[lat][particles] = dict()\n",
    "        log_avg_count_lat[lat][particles] = dict()\n",
    "        log_box_sizes_lat[lat][particles] = dict()\n",
    "        for probability in simulation_probabilities[lat]:\n",
    "            try:\n",
    "                log_box_count_lat[lat][particles][probability] = np.log(box_count_lat_file[lat][particles][probability][0])\n",
    "                log_avg_count_lat[lat][particles][probability] = np.log(avg_count_lat_file[lat][particles][probability][0])\n",
    "                log_box_sizes_lat[lat][particles][probability] = np.log(box_sizes_lat_file[lat][particles][probability][0])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "print(log_box_count_lat)\n",
    "print(log_avg_count_lat)\n",
    "print(log_box_sizes_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Linearization\n",
    "linear_box_count_lat = dict()\n",
    "for lat in lat_size:\n",
    "    linear_box_count_lat[lat] = dict()\n",
    "    for particles in simulations[lat]:\n",
    "        if particles in log_box_count_lat[lat]:\n",
    "            linear_box_count_lat[lat][particles] = dict()\n",
    "        for probability in simulation_probabilities[lat]:\n",
    "            if probability in log_box_count_lat[lat][particles]:\n",
    "                linear_box_count_lat[lat][particles][probability] = dict()\n",
    "                linear_box_count_lat[lat][particles][probability]['pcount'] = linearReg(log_box_sizes_lat[lat][particles][probability], log_avg_count_lat[lat][particles][probability])\n",
    "                linear_box_count_lat[lat][particles][probability]['bcount'] = linearReg(log_box_sizes_lat[lat][particles][probability], log_box_count_lat[lat][particles][probability])\n",
    "                \n",
    "print(linear_box_count_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Df for same density\n",
    "particular_density = (8384 * np.pi/4)/(512**2)\n",
    "particular_lat = [128, 256, 512]\n",
    "particular_part = [524, 2098, 8384]\n",
    "particular_probs = [0.01, 0.015]\n",
    "labels = []\n",
    "avg_fractal_dim = []\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "for lat, c in zip(particular_lat, colors):\n",
    "    for part in particular_part:\n",
    "        for prob, m in zip(particular_probs, markers):\n",
    "            try:\n",
    "                plt.scatter(lat, (linear_box_count_lat[lat][part][prob]['pcount'][0] - linear_box_count_lat[lat][part][prob]['bcount'][0])/ 2, color=c, marker=m, s=50, label = f\"Particles: {part}, Probability: {prob}\")\n",
    "                avg_fractal_dim.append((linear_box_count_lat[lat][part][prob]['pcount'][0] - linear_box_count_lat[lat][part][prob]['bcount'][0]) / 2)\n",
    "                labels.append(f\"Lat Size: {lat}, \\nParticles: {part},\\n Probability: {prob}\")\n",
    "            except:\n",
    "                continue\n",
    "plt.title(f\"Average Fractal Dimensios for Different Systems with Density {particular_density:.4f}\", fontsize = 16)\n",
    "plt.xlabel(\"Lattice Size\", fontsize=16)\n",
    "plt.ylabel(\"Fractal Dimension\", fontsize=16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylim(0,1.5)\n",
    "plt.legend(fontsize=16)\n",
    "plt.savefig(\"../Imagenes/DimensionFractalvsDensidadCnst.png\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.title(f\"Average Fractal Dimensios for Different Systems with Density {particular_density:.4f}\", fontsize = 16)\n",
    "plt.bar(labels, avg_fractal_dim, color=\"darkblue\")\n",
    "plt.ylabel(\"Fractal Dimension\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16, rotation=90)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.savefig(\"../Imagenes/DimensionFractalvsDensidadBAR.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Df Vs. Prob\n",
    "handles = []\n",
    "plt.figure(figsize=(12,9))\n",
    "for lat, c in zip([512], colors[1:]):\n",
    "    for part, m in zip(simulations[lat], markers):\n",
    "        handles.append(Line2D([], [], color=c, marker=m, linestyle='None',\n",
    "                          markersize=10, label=f\"Lat Size: {lat}, Particles: {part}\"))\n",
    "        probs = []\n",
    "        frac_dims = []\n",
    "        for prob in simulation_probabilities[lat]:\n",
    "            try:\n",
    "                frac_dims.append((linear_box_count_lat[lat][part][prob]['pcount'][0] - linear_box_count_lat[lat][part][prob]['bcount'][0])/ 2)\n",
    "                probs.append(prob)\n",
    "            except:\n",
    "                continue\n",
    "        plt.plot(probs, frac_dims, color=c, marker=m, markersize=10)\n",
    "plt.title(f\"Average Fractal Dimensios for Different Probabilities\", fontsize = 16)\n",
    "plt.xlabel(\"Probability\", fontsize=16)\n",
    "plt.ylabel(\"Fractal Dimension\", fontsize=16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "# plt.ylim(0,1.5)\n",
    "plt.legend(handles=handles, fontsize=16)\n",
    "plt.savefig(\"../Imagenes/DimensionFractalvsProb.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Df varying Density\n",
    "\n",
    "handles = []\n",
    "plt.figure(figsize=(12,9))\n",
    "for lat in [512]:\n",
    "    for part, c  in zip(simulations[lat], colors):\n",
    "        densities = []\n",
    "        frac_dims = []\n",
    "        for prob, m in zip(simulation_probabilities[lat], markers):\n",
    "            try:\n",
    "                frac_dims.append((linear_box_count_lat[lat][part][prob]['pcount'][0] - linear_box_count_lat[lat][part][prob]['bcount'][0])/ 2)\n",
    "                densities.append((part * (np.pi/4)) / (lat ** 2))\n",
    "                handles.append(Line2D([], [], color=c, marker=m, linestyle='None',\n",
    "                          markersize=10, label=f\"Lat Size: {lat}, Particles: {part}, Probability: {prob}\"))\n",
    "                plt.scatter(densities, frac_dims, color=c, marker=m, s=50)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "plt.title(f\"Average Fractal Dimensios for Different Probabilities\", fontsize = 16)\n",
    "plt.xlabel(\"Density\", fontsize=16)\n",
    "plt.ylabel(\"Fractal Dimension\", fontsize=16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylim(0,1.6)\n",
    "plt.legend(handles=handles, fontsize=16)\n",
    "plt.savefig(\"../Imagenes/DimensionFractalvsDens.png\")\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Coordination Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinationNumbers(lat_size, particles, prob):\n",
    "    zs = []\n",
    "    mean = df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)].mean()[6:]  #Change slice to adequate value\n",
    "    for i, val in enumerate(mean):\n",
    "            zs.append(mean[i] / particles)\n",
    "    return zs\n",
    "\n",
    "plt.figure(figsize = (9, 9))\n",
    "legend_elements = []\n",
    "\n",
    "custom_labels = []\n",
    "for lat, marker in zip(lat_size, markers):\n",
    "    for particles in [simulations[lat][0]]:\n",
    "        custom_labels.append(Line2D([0], [0], color='k', marker=marker, markersize=10, label=f\"Lat Size: {lat}, Particles = {particles}\"))\n",
    "        zs_total = []\n",
    "        for prob in simulation_probabilities[lat]:\n",
    "            zs = coordinationNumbers(lat, particles, prob)\n",
    "            if zs:\n",
    "                zs_total.append(zs)\n",
    "\n",
    "        if zs_total:\n",
    "            for j, zs in enumerate(zip(*zs_total)):\n",
    "                plt.plot(simulation_probabilities[lat], zs, color = colors[j], marker=marker,markersize=10)\n",
    "\n",
    "for i in range(7):\n",
    "    custom_labels.append(Line2D([0], [0], color=colors[i], label=f\"z = {i}\"))\n",
    "\n",
    "plt.title(f\"Mean Coordination Number vs Probability of Separation for {simulation_densities[512][0]:.3f} Density\", fontsize = 16)\n",
    "plt.xlabel(\"Probability\", fontsize = 16)\n",
    "plt.ylabel(\"Percentage of Particles\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend(handles=custom_labels, fontsize = 16, loc = (1.0, 0.25))\n",
    "# plt.savefig(\"Result Images/ResultsZ_Off.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (9, 9))\n",
    "linestyles = ['-', '--', '-.', ':', \"solid\"]\n",
    "legend_elements = []\n",
    "\n",
    "custom_labels = []\n",
    "lat = 512\n",
    "for density, particles, marker, ls in zip(simulation_densities[lat], simulations[lat], markers, linestyles):\n",
    "    custom_labels.append(Line2D([0], [0], color='k', linestyle=ls, marker=marker, markersize=10, label=f\"Particles = {particles}\"))\n",
    "    zs_total = []\n",
    "    for prob in simulation_probabilities[lat]:\n",
    "        zs = coordinationNumbers(lat, particles, prob)\n",
    "        if zs:\n",
    "            zs_total.append(zs)\n",
    "\n",
    "    if zs_total:\n",
    "        for j, zs in enumerate(zip(*zs_total)):\n",
    "            plt.plot(simulation_probabilities[lat], zs, color = colors[j], marker=marker,markersize=10, linestyle=ls)\n",
    "\n",
    "for i in range(7):\n",
    "    custom_labels.append(Line2D([0], [0], color=colors[i], label=f\"z = {i}\"))\n",
    "\n",
    "plt.title(f\"Mean Coordination Number vs Probability Separation for Lat Size = {lat} for Different Densities\", fontsize = 16)\n",
    "plt.xlabel(\"Probability\", fontsize = 16)\n",
    "plt.ylabel(\"Percentage of Particles\", fontsize = 16)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.legend(handles=custom_labels, fontsize = 16, loc = (1.0, 0.25))\n",
    "plt.savefig(\"../Imagenes/ResultsZ.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg. Cluster Mass Per Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def massStepDict(lat_size, particles, probability):\n",
    "    avg_mass = dict()\n",
    "\n",
    "    mass_time_files = [f for f in os.listdir(path_seagate) if (mass_time_fn in f) and (str(int(lat_size)) in f) and (str(int(particles)) in f) and (f\"{probability:.3f}\" in f) and not (edges_fn in f)]\n",
    "    if (len(mass_time_files) == 0):\n",
    "        return dict()\n",
    "\n",
    "    for file_name in mass_time_files:\n",
    "        try:\n",
    "            data = np.loadtxt(path_seagate + file_name, delimiter=',')\n",
    "            for line in data:\n",
    "                if line[0] in avg_mass:\n",
    "                    avg_mass[line[0]][0] = avg_mass[line[0]][0] + 1\n",
    "                    avg_mass[line[0]][1].append(particles/np.sum(line[1:]))\n",
    "                else:\n",
    "                    avg_mass[line[0]] = [1, [particles/np.sum(line[1:])]]\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "\n",
    "    return dict(sorted(avg_mass.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_mass_dicts = []\n",
    "avg_mass_total_mean = []\n",
    "for lat in [512]:\n",
    "    for particles in simulations[lat]:\n",
    "        for prob in simulation_probabilities[lat]:\n",
    "            avg_mass = massStepDict(lat, particles, prob)\n",
    "            if avg_mass:\n",
    "                avg_mass_total = []\n",
    "                plt.figure(figsize = (15,9))\n",
    "                for step_num in avg_mass:\n",
    "                    plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "                    avg_mass_total.append(np.mean(avg_mass[step_num][1]))\n",
    "\n",
    "                avg_mass_dicts.append(avg_mass)\n",
    "                print(f\"Plotting L = {lat}, Particles = {particles}, and Prob = {prob}\")\n",
    "                plt.title(f\"Average Cluster Mass for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\")\n",
    "                plt.xlabel(\"Num Steps\")\n",
    "                plt.ylabel(\"Avg Mass\")\n",
    "                plt.plot(avg_mass.keys(), avg_mass_total, marker = \"o\")\n",
    "                plt.savefig(f\"../Imagenes/AverageMass{lat}Particles{particles}Prob{prob}.png\")\n",
    "                avg_mass_total_mean.append(avg_mass_total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Softening previous curves\n",
    "titles = [f\"Average Cluster Mass for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\" for lat in [512] for particles in simulations[lat] for prob in simulation_probabilities[lat] if len(df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)]) != 0]\n",
    "\n",
    "particles_plot = [particles for lat in [512] for particles in simulations[lat] for prob in simulation_probabilities[lat] if len(df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)]) != 0]\n",
    "prob_plot = [prob for lat in [512] for particles in simulations[lat] for prob in simulation_probabilities[lat] if len(df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)]) != 0]\n",
    "\n",
    "\n",
    "steps_soft_all_avg = []\n",
    "avg_avg_soft_all = []\n",
    "for i, (avg_mass, avg_mass_total) in enumerate(zip(avg_mass_dicts, avg_mass_total_mean)):\n",
    "    steps_soft = soften(list(avg_mass.keys()), len(avg_mass.keys())//50)\n",
    "    mass_soft = soften(avg_mass_total, len(avg_mass_total)//50)\n",
    "    if avg_mass:\n",
    "        plt.figure(figsize = (15,9))\n",
    "        for step_num in avg_mass:\n",
    "                plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "        plt.title(titles[i])\n",
    "        plt.xlabel(\"Num Steps\")\n",
    "        plt.ylabel(\"Size of Clusters\")\n",
    "        plt.plot(steps_soft[:-1], mass_soft[:-1], marker = \"o\") \n",
    "\n",
    "        plt.savefig(f\"../Imagenes/SoftAverageMass{512}Particles{particles_plot[i]}Prob{prob_plot[i]}.png\") \n",
    "\n",
    "        steps_soft_all_avg.append(steps_soft)\n",
    "        avg_avg_soft_all.append(mass_soft)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Clusters vs Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numClustersStepDict(lat_size, particles, probability):\n",
    "    avg_mass = dict()\n",
    "\n",
    "    mass_time_files = [f for f in os.listdir(path_seagate) if (mass_time_fn in f) and (str(int(lat_size)) in f) and (str(int(particles)) in f) and (f\"{probability:.3f}\" in f) and not (edges_fn in f)]\n",
    "    if (len(mass_time_files) == 0):\n",
    "        return dict()\n",
    "\n",
    "    for file_name in mass_time_files:\n",
    "        try:\n",
    "            data = np.loadtxt(path_seagate + file_name, delimiter=',')\n",
    "            for line in data:\n",
    "                if line[0] in avg_mass:\n",
    "                    avg_mass[line[0]][0] = avg_mass[line[0]][0] + 1\n",
    "                    avg_mass[line[0]][1].append(np.sum(line[1:]))\n",
    "                else:\n",
    "                    avg_mass[line[0]] = [1, [np.sum(line[1:])]]\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "\n",
    "    return dict(sorted(avg_mass.items()))\n",
    "\n",
    "\n",
    "num_clusters_dicts = []\n",
    "num_clusters_total_mean = []\n",
    "for lat in [512]:\n",
    "    for particles in simulations[lat]:\n",
    "        for prob in simulation_probabilities[lat]:\n",
    "            avg_mass = numClustersStepDict(lat, particles, prob)\n",
    "            if avg_mass:\n",
    "                avg_mass_total = []\n",
    "                plt.figure(figsize = (15,9))\n",
    "                for step_num in avg_mass:\n",
    "                    plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "                    avg_mass_total.append(np.mean(avg_mass[step_num][1]))\n",
    "\n",
    "                num_clusters_dicts.append(avg_mass)\n",
    "                print(f\"Plotting L = {lat}, Particles = {particles}, and Prob = {prob}\")\n",
    "                plt.title(f\"Average Number of Clusters for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\")\n",
    "                plt.xlabel(\"Num Steps\")\n",
    "                plt.ylabel(\"Num. Clusters\")\n",
    "                plt.plot(avg_mass.keys(), avg_mass_total, marker = \"o\")\n",
    "                plt.savefig(f\"../Imagenes/NumClustersSize{lat}Particles{particles}Prob{prob}.png\")\n",
    "                num_clusters_total_mean.append(avg_mass_total)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Largest Cluster Size vs Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargestFilledIndex(array):\n",
    "    i = -1\n",
    "    for j, val in enumerate(array):\n",
    "        if val != 0:\n",
    "            i = j+1\n",
    "\n",
    "    return i\n",
    "\n",
    "def largestClustersStepDict(lat_size, particles, probability):\n",
    "    avg_mass = dict()\n",
    "\n",
    "    mass_time_files = [f for f in os.listdir(path_seagate) if (mass_time_fn in f) and (str(int(lat_size)) in f) and (str(int(particles)) in f) and (f\"{probability:.3f}\" in f) and not (edges_fn in f)]\n",
    "    if not mass_time_files:\n",
    "        return dict()\n",
    "\n",
    "    for file_name in mass_time_files:\n",
    "        try:\n",
    "            data = np.loadtxt(path_seagate + file_name, delimiter=',')\n",
    "            for line in data:\n",
    "                if line[0] in avg_mass:\n",
    "                    avg_mass[line[0]][0] = avg_mass[line[0]][0] + 1\n",
    "                    avg_mass[line[0]][1].append(getLargestFilledIndex(line[1:]))\n",
    "                else:\n",
    "                    avg_mass[line[0]] = [1, [getLargestFilledIndex(line[1:])]]\n",
    "        except: \n",
    "            continue    \n",
    "\n",
    "    return dict(sorted(avg_mass.items()))\n",
    "\n",
    "\n",
    "avg_largest_dicts = []\n",
    "avg_largest_mean = []\n",
    "for lat in lat_size:\n",
    "    for particles in simulations[lat]:\n",
    "        for prob in simulation_probabilities[lat]:\n",
    "            avg_mass = largestClustersStepDict(lat, particles, prob)\n",
    "            if avg_mass:\n",
    "                avg_largest = []\n",
    "                plt.figure(figsize = (15,9))\n",
    "                for step_num in avg_mass:\n",
    "                    plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "                    avg_largest.append(np.mean(avg_mass[step_num][1]))\n",
    "\n",
    "                avg_largest_dicts.append(avg_mass)\n",
    "                print(f\"Plotting L = {lat}, Particles = {particles}, and Prob = {prob}\")\n",
    "                plt.title(f\"Largest Cluster Size for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\")\n",
    "                plt.xlabel(\"Num Steps\")\n",
    "                plt.ylabel(\"Size of Clusters\")\n",
    "                plt.plot(avg_mass.keys(), avg_largest, marker = \"o\")\n",
    "                plt.savefig(f\"../Imagenes/LargestCluster{lat}Particles{particles}Prob{prob}.png\")\n",
    "                avg_largest_mean.append(avg_largest)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Softening previous curves\n",
    "titles = [f\"Largest Cluster Size for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\" for lat in lat_size for particles in simulations[lat] for prob in simulation_probabilities[lat] if len(df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)]) != 0]\n",
    "\n",
    "\n",
    "particles_plot = [particles for lat in lat_size for particles in simulations[lat] for prob in simulation_probabilities[lat] if len(df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)]) != 0]\n",
    "prob_plot = [prob for lat in lat_size for particles in simulations[lat] for prob in simulation_probabilities[lat] if len(df[(df['num_particles'] == particles) & (df['lattice_size'] == lat) & (df['probability'] == prob)]) != 0]\n",
    "\n",
    "\n",
    "steps_soft_all_largest = []\n",
    "avg_largest_soft_all = []\n",
    "for i, (avg_mass, avg_largest) in enumerate(zip(avg_largest_dicts, avg_largest_mean)):\n",
    "    steps_soft = soften(list(avg_mass.keys()), len(avg_mass.keys())//50)\n",
    "    mass_soft = soften(avg_largest, len(avg_largest)//50)\n",
    "    if avg_mass:\n",
    "        plt.figure(figsize = (15,9))\n",
    "        # for step_num in avg_mass:\n",
    "                # plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "        plt.title(titles[i])\n",
    "        plt.xlabel(\"Num Steps\")\n",
    "        plt.ylabel(\"Size of Clusters\")\n",
    "        plt.plot(steps_soft[:-1], mass_soft[:-1], marker = \"o\")  \n",
    "        plt.savefig(f\"../Imagenes/SoftLargestMass{512}Particles{particles_plot[i]}Prob{prob_plot[i]}.png\") \n",
    "\n",
    "        steps_soft_all_largest.append(steps_soft)\n",
    "        avg_largest_soft_all.append(mass_soft)\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying probability and plotting same densities together\n",
    "particular_lat = 512\n",
    "i = 14\n",
    "for particles in simulations[particular_lat]:\n",
    "    plt.figure(figsize=(15,9))\n",
    "    for prob, c in zip(simulation_probabilities[particular_lat], colors):\n",
    "        plt.plot(steps_soft_all_largest[i][:-1], avg_largest_soft_all[i][:-1], color=c, label=f\"Particles = {particles}\\nProbability = {prob}\")\n",
    "        plt.title(f\"Largest Cluster for Every Step Taken for L = {particular_lat} with Density = {(particles * (np.pi/4)) / (particular_lat**2):.4f}\")\n",
    "        plt.xlabel(\"Number of Steps\")\n",
    "        plt.ylabel(\"Mass of Largest Cluster\")\n",
    "        plt.legend()\n",
    "        plt.savefig(f\"../Imagenes/LargestClusterVaryingL{particular_lat}Particles{particles}\")\n",
    "        \n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying probability and plotting same densities together\n",
    "particular_lat = 512\n",
    "i = 14\n",
    "for particles in simulations[particular_lat]:\n",
    "    plt.figure(figsize=(15,9))\n",
    "    for prob, c in zip(simulation_probabilities[particular_lat], colors):\n",
    "        if (i < 22 and prob != 0.01) or (i >=22 and prob != 0.015 and prob != 0.01):\n",
    "            plt.plot(steps_soft_all_largest[i][:-1], avg_largest_soft_all[i][:-1], color=c, label=f\"Probability = {prob}\")\n",
    "            plt.title(f\"Largest Cluster for Every Step Taken for L = {particular_lat}, Particles = {particles}, and Density = {(particles * (np.pi/4)) / (particular_lat**2):.4f}\")\n",
    "            plt.xlabel(\"Number of Steps\")\n",
    "            plt.ylabel(\"Mass of Largest Cluster\")\n",
    "            plt.legend()\n",
    "\n",
    "            plt.savefig(f\"../Imagenes/ReducedLargestClusterVaryingL{particular_lat}Particles{particles}\")\n",
    "\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying density and plotting same porbabilities together\n",
    "particular_lat = 512\n",
    "plots = []\n",
    "figs = []\n",
    "for i in range(4):\n",
    "    plot = plt.figure(figsize=(15,9))\n",
    "    ax = plot.add_subplot(1,1,1)\n",
    "    plots.append(ax)\n",
    "    figs.append(plot)\n",
    "\n",
    "cont = 14\n",
    "i = 0\n",
    "for particles, c in zip(simulations[particular_lat], colors):\n",
    "    j = 0\n",
    "    for prob in simulation_probabilities[particular_lat]:\n",
    "        if i == 0:\n",
    "            plots[j].set_title(f\"Largest Cluster for Every Step Taken for L = {particular_lat} and Probability = {prob}\")\n",
    "            plots[j].set_xlabel(\"Number of Steps\")\n",
    "            plots[j].set_ylabel(\"Normalized Mass of Largest Cluster\")\n",
    "        \n",
    "        plots[j].plot(steps_soft_all_largest[cont][:-1], np.array(avg_largest_soft_all[cont][:-1])/particles , color=c, label=f\"Particles = {particles}\")\n",
    "\n",
    "        j += 1\n",
    "        cont += 1\n",
    "\n",
    "    i += 1\n",
    "\n",
    "for i in range(4):\n",
    "    plots[i].legend()\n",
    "    figs[i].savefig(f\"../Imagenes/LargestClusterVaryingL{particular_lat}Probability{simulation_probabilities[particular_lat][i]}.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Percolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_percolation = []\n",
    "labels = []\n",
    "percolation_colors = []\n",
    "for lat in [512]:\n",
    "    for particles in simulations[lat]:\n",
    "        for i, prob in enumerate(simulation_probabilities[lat]):\n",
    "            if not ((particles == 8384 and prob == 0.015) or (particles == 12582 and prob == 0.02) and (particles == 14680 and prob == 0.02)):\n",
    "                if (len(df[(df.num_particles == particles) & (df.probability == prob) & (df.lattice_size == lat)]) != 0):\n",
    "                    perc_percolation.append(df[(df.num_particles == particles) & (df.probability == prob) & (df.lattice_size == lat)].percolation.mean())\n",
    "                    labels.append(f\"L = {lat}, P = {particles} & Prob = {prob}\")\n",
    "                    percolation_colors.append(colors[i+1])\n",
    "\n",
    "print(perc_percolation)\n",
    "plt.figure(figsize = (15,9))\n",
    "plt.bar(labels, perc_percolation, color = percolation_colors)\n",
    "plt.title(\"Percentage of Particles that Percolate vs. Simulated Clusters\", fontsize = 16)\n",
    "plt.xlabel(\"Probability and Size\", fontsize = 16)\n",
    "plt.ylabel(\"Percentage of Particles\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16, rotation=90)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.grid(axis='y')\n",
    "plt.savefig(f\"../Imagenes/PercolateOffRevSimplified.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GrÃ¡ficas simulaciones largas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "def getLargestFilledIndex(array):\n",
    "    i = -1\n",
    "    for j, val in enumerate(array):\n",
    "        if val != 0:\n",
    "            i = j+1\n",
    "\n",
    "    return i\n",
    "\n",
    "\n",
    "def longSims(file_name):\n",
    "    steps = []\n",
    "    largest = []\n",
    "    with open(file_name, 'r') as f:\n",
    "        csv_reader = reader(f)\n",
    "        for row in csv_reader:\n",
    "            steps.append(int(row[0]))\n",
    "            largest.append(getLargestFilledIndex(row[1:]))\n",
    "\n",
    "    return steps, largest\n",
    "\n",
    "file_name = [\"Results/NumberTimeSize512Particles10486Prob0.020000.csv\", \"Results/NumberTimeSize512Particles15728Prob0.030000.csv\"]\n",
    "titles = [\"Largest Cluster for Every Step Taken L = 512, Particles = 10486 and Probability = 0.02\",\n",
    "            \"Largest Cluster for Every Step Taken L = 512, Particles = 15728 and Probability = 0.03\"]\n",
    "for f, title in zip(file_name, titles):\n",
    "    print(f\"Getting x and y values for {title}\")\n",
    "    x, y = longSims(f)\n",
    "\n",
    "    print(\"Softening\")\n",
    "    print(len(x), len(y))\n",
    "    x_soft = soften(x, len(x)//1000)\n",
    "    y_soft = soften(y, len(y)//1000)\n",
    "    print(\"Plotting\")\n",
    "    plt.figure(figsize=(12,9))\n",
    "    plt.plot(x_soft, y_soft, marker='o')\n",
    "    plt.xlabel(\"Num Steps\")\n",
    "    plt.ylabel(\"Largest Cluster\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edges = pd.read_csv(\"Final Results/ResultsOffLEdge.csv\")\n",
    "lat_size_edges = df_edges.lattice_size.unique()\n",
    "lat_size_edges.sort()\n",
    "print(lat_size_edges)\n",
    "\n",
    "radius = 1\n",
    "\n",
    "simulation_edges = dict()\n",
    "simulation_probabilities_edges = dict()\n",
    "simulation_densities_edges = dict()\n",
    "for lat in lat_size_edges:\n",
    "    simulation_edges[lat] = sorted(list(df_edges[df_edges.lattice_size == lat].num_particles.unique()))\n",
    "    simulation_probabilities_edges[lat] = sorted(list(df_edges[df_edges.lattice_size == lat].probability.unique()))\n",
    "    simulation_densities_edges[lat] = [(particles * np.pi * (radius ** 2)) / (4 * (lat ** 2)) for particles in sorted(list(df_edges[df_edges.lattice_size == lat].num_particles.unique()))]\n",
    "\n",
    "print(simulation_edges)\n",
    "print(simulation_probabilities_edges)\n",
    "print(simulation_densities_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "box_count_lat_edges = dict()\n",
    "avg_count_lat_edges = dict()\n",
    "box_sizes_lat_edges = dict()\n",
    "\n",
    "for lat in lat_size_edges:\n",
    "    box_count_lat_edges[lat] = dict()\n",
    "    avg_count_lat_edges[lat] = dict()\n",
    "    box_sizes_lat_edges[lat] = dict()\n",
    "    for particles in simulation_edges[lat]:\n",
    "        box_count_lat_edges[lat][particles] = dict()\n",
    "        avg_count_lat_edges[lat][particles] = dict()\n",
    "        box_sizes_lat_edges[lat][particles] = dict()\n",
    "        for probability in simulation_probabilities_edges[lat]:\n",
    "            box_counts_list = []\n",
    "            avg_counts_list = []\n",
    "            box_sizes_list = []\n",
    "\n",
    "            text_files = [f for f in os.listdir(path_seagate) if (cluster_fn in f) and (str(int(lat)) in f) and (str(int(particles)) in f) and (str(float(probability)) in f) and (edges_fn in f)]\n",
    "            if text_files:\n",
    "                box_count_lat_edges[lat][particles][probability] = []\n",
    "                avg_count_lat_edges[lat][particles][probability] = []\n",
    "                box_sizes_lat_edges[lat][particles][probability] = []\n",
    "                print(f\"Computing Fractal Dims for Lat = {lat}, Particles = {particles} and Probability = {probability} Edges\")\n",
    "                for file_i in text_files:\n",
    "                    cluster = np.loadtxt(path_seagate + '/' + file_i, delimiter = ',')\n",
    "\n",
    "                    x, y, index, z = np.hsplit(cluster, cluster.shape[1])\n",
    "                    x = x.flatten()\n",
    "                    y = y.flatten()\n",
    "                    indexes = index.flatten().astype(int)\n",
    "                    largest_cluster = int(stats.mode(indexes).mode)\n",
    "\n",
    "                    x_index = x[np.where(indexes == largest_cluster)]\n",
    "                    y_index = y[np.where(indexes == largest_cluster)]\n",
    "            \n",
    "                    if len(x_index) > 500:\n",
    "                        with blockPrint():\n",
    "                            box_count, avg_counts, box_size = boxCount(lat, len(x_index), x_index, y_index)\n",
    "                        plt.close('all')\n",
    "\n",
    "                        box_counts_list.append(box_count)\n",
    "                        avg_counts_list.append(avg_counts)\n",
    "                        box_sizes_list.append(box_size)\n",
    "\n",
    "            if box_counts_list:\n",
    "                box_count_avg_p = np.mean(box_counts_list, axis = 0)\n",
    "                avg_count_avg_p = np.mean(avg_counts_list, axis = 0)\n",
    "                box_sizes_avg_p = np.mean(box_sizes_list, axis = 0)\n",
    "                box_count_lat_edges[lat][particles][probability].append(box_count_avg_p)\n",
    "                avg_count_lat_edges[lat][particles][probability].append(avg_count_avg_p)\n",
    "                box_sizes_lat_edges[lat][particles][probability].append(box_sizes_avg_p)\n",
    "\n",
    "print(box_count_lat_edges)\n",
    "\n",
    "print(\"Computing logarithm of Lists\")\n",
    "log_box_sizes_lat_edges = dict() # log average box count list\n",
    "log_box_count_lat_edges = dict() # log average average particle count list\n",
    "log_avg_count_lat_edges = dict() # log average box size list\n",
    "\n",
    "for lat in lat_size_edges:\n",
    "    log_box_count_lat_edges[lat] = dict()\n",
    "    log_avg_count_lat_edges[lat] = dict()\n",
    "    log_box_sizes_lat_edges[lat] = dict()\n",
    "    for particles in simulation_edges[lat]:\n",
    "        log_box_count_lat_edges[lat][particles] = dict()\n",
    "        log_avg_count_lat_edges[lat][particles] = dict()\n",
    "        log_box_sizes_lat_edges[lat][particles] = dict()\n",
    "        for probability in simulation_probabilities_edges[lat]:\n",
    "            try:\n",
    "                log_box_count_lat_edges[lat][particles][probability] = np.log(box_count_lat_edges[lat][particles][probability][0])\n",
    "                log_avg_count_lat_edges[lat][particles][probability] = np.log(avg_count_lat_edges[lat][particles][probability][0])\n",
    "                log_box_sizes_lat_edges[lat][particles][probability] = np.log(box_sizes_lat_edges[lat][particles][probability][0])\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "print(\"Logs completed\")\n",
    "print(log_box_sizes_lat_edges)\n",
    "# Linearization\n",
    "linear_box_count_lat_edges = dict()\n",
    "for lat in lat_size_edges:\n",
    "    linear_box_count_lat_edges[lat] = dict()\n",
    "    for particles in simulation_edges[lat]:\n",
    "        if particles in log_box_count_lat_edges[lat]:\n",
    "            linear_box_count_lat_edges[lat][particles] = dict()\n",
    "        for probability in simulation_probabilities_edges[lat]:\n",
    "            if probability in log_box_count_lat_edges[lat][particles]:\n",
    "                linear_box_count_lat_edges[lat][particles][probability] = dict()\n",
    "                linear_box_count_lat_edges[lat][particles][probability]['pcount'] = linearReg(log_box_sizes_lat_edges[lat][particles][probability], log_avg_count_lat_edges[lat][particles][probability])\n",
    "                linear_box_count_lat_edges[lat][particles][probability]['bcount'] = linearReg(log_box_sizes_lat_edges[lat][particles][probability], log_box_count_lat_edges[lat][particles][probability])\n",
    "\n",
    "print(\"Linearization Complete\")\n",
    "print(linear_box_count_lat_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "avg_fractal_dim = []\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "for lat, c in zip(lat_size_edges, colors):\n",
    "    for part in simulation_edges[lat]:\n",
    "        for prob, m in zip(simulation_probabilities_edges[lat], markers):\n",
    "            try:\n",
    "                plt.scatter(part, (linear_box_count_lat_edges[lat][part][prob]['pcount'][0] - linear_box_count_lat_edges[lat][part][prob]['bcount'][0])/ 2, color=c, marker=m, s=50, label = f\"Lat Size: {lat}, Probability: {prob}\")\n",
    "                \n",
    "                avg_fractal_dim.append((linear_box_count_lat_edges[lat][part][prob]['pcount'][0] - linear_box_count_lat_edges[lat][part][prob]['bcount'][0]) / 2)\n",
    "                labels.append(f\"Lat Size: {lat}, \\nParticles: {part},\\n Probability: {prob}\")\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "plt.title(f\"Average Fractal Dimensios for Different Systems with Density {simulation_densities_edges[512][0]:.4f}\", fontsize = 16)\n",
    "plt.xlabel(\"Lattice Size\", fontsize=16)\n",
    "plt.ylabel(\"Fractal Dimension\", fontsize=16)\n",
    "plt.xticks(fontsize = 16)\n",
    "plt.yticks(fontsize = 16)\n",
    "plt.ylim(0,1.5)\n",
    "plt.savefig(f\"../Imagenes/AverageFractalDimEdgesRev\")\n",
    "plt.legend(fontsize=16)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.title(f\"Average Fractal Dimensios for Different Systems with Density {simulation_densities_edges[512][1]:.4f}\", fontsize = 16)\n",
    "plt.bar(labels, avg_fractal_dim, color=\"darkblue\")\n",
    "plt.ylabel(\"Fractal Dimension\", fontsize = 16)\n",
    "plt.xticks(fontsize = 16, rotation=90)\n",
    "plt.yticks(fontsize = 16)\n",
    "# plt.ylim(0,1.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLargestFilledIndex(array):\n",
    "    i = -1\n",
    "    for j, val in enumerate(array):\n",
    "        if val != 0:\n",
    "            i = j+1\n",
    "\n",
    "    return i\n",
    "\n",
    "def largestClustersStepDictEdges(lat_size, particles, probability):\n",
    "    avg_mass = dict()\n",
    "\n",
    "    mass_time_files = [f for f in os.listdir(path_seagate) if (mass_time_fn in f) and (str(int(lat_size)) in f) and (str(int(particles)) in f) and (f\"{probability:.3f}\" in f) and (edges_fn in f)]\n",
    "    if not mass_time_files:\n",
    "        return dict()\n",
    "\n",
    "    for file_name in mass_time_files:\n",
    "        try:\n",
    "            data = np.loadtxt(path_seagate + file_name, delimiter=',')\n",
    "            for line in data:\n",
    "                if line[0] in avg_mass:\n",
    "                    avg_mass[line[0]][0] = avg_mass[line[0]][0] + 1\n",
    "                    avg_mass[line[0]][1].append(getLargestFilledIndex(line[1:]))\n",
    "                else:\n",
    "                    avg_mass[line[0]] = [1, [getLargestFilledIndex(line[1:])]]\n",
    "        except: \n",
    "            continue    \n",
    "\n",
    "    return dict(sorted(avg_mass.items()))\n",
    "\n",
    "avg_largest_dicts_edges = []\n",
    "mean_plot_averages_edge = []\n",
    "for lat in lat_size_edges:\n",
    "    for particles in simulation_edges[lat]:\n",
    "        for prob in simulation_probabilities_edges[lat]:\n",
    "            avg_mass = largestClustersStepDictEdges(lat, particles, prob)\n",
    "            if avg_mass:\n",
    "                mean_plot = []\n",
    "                plt.figure(figsize = (15,9))\n",
    "                for step_num in avg_mass:\n",
    "                    plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "                    mean_plot.append(np.mean(avg_mass[step_num][1]))\n",
    "                avg_largest_dicts_edges.append(avg_mass)\n",
    "                print(f\"Plotting L = {lat}, Particles = {particles}, and Prob = {prob}\")\n",
    "                plt.title(f\"Largest Cluster Size for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\")\n",
    "                plt.xlabel(\"Num Steps\")\n",
    "                plt.ylabel(\"Size of Clusters\")\n",
    "                plt.plot(avg_mass.keys(), mean_plot, marker = \"o\")\n",
    "                mean_plot_averages_edge.append(mean_plot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softening previous curves\n",
    "titles = [f\"Largest Edge Cluster Size for Every Step Taken L = {lat}, Particles = {particles} and Probability = {prob}\" for lat in [512] for particles in simulations_edges[lat] for prob in simulation_probabilities_edges[lat] if len(df_edges[(df_edges['num_particles'] == particles) & (df_edges['lattice_size'] == lat) & (df_edges['probability'] == prob)]) != 0]\n",
    "\n",
    "\n",
    "particles_plot = [particles for lat in [512] for particles in simulations_edges[lat] for prob in simulation_probabilities_edges[lat] if len(df_edges[(df_edges['num_particles'] == particles) & (df_edges['lattice_size'] == lat) & (df_edges['probability'] == prob)]) != 0]\n",
    "prob_plot = [prob for lat in [512] for particles in simulations_edges[lat] for prob in simulation_probabilities_edges[lat] if len(df_edges[(df_edges['num_particles'] == particles) & (df_edges['lattice_size'] == lat) & (df_edges['probability'] == prob)]) != 0]\n",
    "\n",
    "\n",
    "steps_soft_all_largest = []\n",
    "avg_largest_soft_all = []\n",
    "for i, (avg_mass, avg_largest) in enumerate(zip(avg_largest_dicts_edges, avg_largest_mean_edge)):\n",
    "    steps_soft = soften(list(avg_mass.keys()), len(avg_mass.keys())//50)\n",
    "    mass_soft = soften(avg_largest, len(avg_largest)//50)\n",
    "    if avg_mass:\n",
    "        plt.figure(figsize = (15,9))\n",
    "        for step_num in avg_mass:\n",
    "                plt.scatter([step_num]*len(avg_mass[step_num][1]), avg_mass[step_num][1], color=colors[1],alpha=0.2)\n",
    "        plt.title(titles[i])\n",
    "        plt.xlabel(\"Num Steps\")\n",
    "        plt.ylabel(\"Size of Clusters\")\n",
    "        plt.plot(steps_soft[:-1], mass_soft[:-1], marker = \"o\")  \n",
    "        plt.savefig(f\"../Imagenes/SoftAverageMass{512}Particles{particles_plot[i]}Prob{prob_plot[i]}Edge.png\") \n",
    "\n",
    "        steps_soft_all_largest.append(steps_soft)\n",
    "        avg_largest_soft_all.append(mass_soft)\n",
    "\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('science': conda)",
   "name": "python388jvsc74a57bd0705053cbbfe07aa18cf8a118e13f4729c51dc087d8c32306bd12d05c66943922"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
